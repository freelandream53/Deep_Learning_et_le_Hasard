{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cas de prédiction du Loto français "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import des librairies utiles\n",
    "import csv\n",
    "import time\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Bidirectional, TimeDistributed, RepeatVector, Flatten\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fonction de scraping des tirages du loto\n",
    "df_tirage = pd.read_csv('eurodata .csv', sep = ',', usecols=['day','month_year','num0','num1','num2','num3','num4','chance'])\n",
    "def sorter(num_arr):\n",
    "    return np.sort(num_arr)\n",
    "df_tirage[['num0', 'num1', 'num2', 'num3', 'num4']] = df_tirage.apply(lambda row : sorter(row[2:-1]), axis=1, result_type='expand')\n",
    "dtype={'num':str, 'chance':int}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonction de scraping des tirages\n",
    "\n",
    "#A noter que plusieurs tirages se sont ajoutés dépuis le 21 : date de rédaction de l'article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>month_year</th>\n",
       "      <th>num0</th>\n",
       "      <th>num1</th>\n",
       "      <th>num2</th>\n",
       "      <th>num3</th>\n",
       "      <th>num4</th>\n",
       "      <th>chance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MARDI</td>\n",
       "      <td>05/07/2022</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>45</td>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VENDREDI</td>\n",
       "      <td>01/07/2022</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>34</td>\n",
       "      <td>46</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MARDI</td>\n",
       "      <td>28/06/2022</td>\n",
       "      <td>10</td>\n",
       "      <td>35</td>\n",
       "      <td>42</td>\n",
       "      <td>47</td>\n",
       "      <td>48</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VENDREDI</td>\n",
       "      <td>24/06/2022</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>28</td>\n",
       "      <td>44</td>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MARDI</td>\n",
       "      <td>21/06/2022</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>36</td>\n",
       "      <td>39</td>\n",
       "      <td>47</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        day  month_year  num0  num1  num2  num3  num4  chance\n",
       "0  MARDI     05/07/2022     7    10    25    45    48       3\n",
       "1  VENDREDI  01/07/2022     6    18    24    34    46      12\n",
       "2  MARDI     28/06/2022    10    35    42    47    48      11\n",
       "3  VENDREDI  24/06/2022    10    17    28    44    50      12\n",
       "4  MARDI     21/06/2022     6    23    36    39    47      10"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sracping des tirages actuellement disponibles sur le site \n",
    "\n",
    "df_tirage[['day','month_year','num0','num1','num2','num3','num4','chance']].head()\n",
    "#suppression  des tirages du super loto( A explorer later )\n",
    "#df_tirage=df_tirage[(df_tirage['day']!='Vendredi') & (df_tirage['day']!='Mardi')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tirage=df_tirage.tail(df_tirage.shape[0]-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## commentaires: \n",
    "* le dernier tirage ici date du 07 décembre, ainsi afin de tester le modèle nous allons rétirer ce tirage du dataset dans la suite\n",
    "* Par contre on aurait évité de supprimer le tirage du 28 si on voulait prédire le prochain tirage ( celui du samedi 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>month_year</th>\n",
       "      <th>num0</th>\n",
       "      <th>num1</th>\n",
       "      <th>num2</th>\n",
       "      <th>num3</th>\n",
       "      <th>num4</th>\n",
       "      <th>chance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VENDREDI</td>\n",
       "      <td>01/07/2022</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>34</td>\n",
       "      <td>46</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MARDI</td>\n",
       "      <td>28/06/2022</td>\n",
       "      <td>10</td>\n",
       "      <td>35</td>\n",
       "      <td>42</td>\n",
       "      <td>47</td>\n",
       "      <td>48</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VENDREDI</td>\n",
       "      <td>24/06/2022</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>28</td>\n",
       "      <td>44</td>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MARDI</td>\n",
       "      <td>21/06/2022</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>36</td>\n",
       "      <td>39</td>\n",
       "      <td>47</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>VENDREDI</td>\n",
       "      <td>17/06/2022</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>31</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        day  month_year  num0  num1  num2  num3  num4  chance\n",
       "1  VENDREDI  01/07/2022     6    18    24    34    46      12\n",
       "2  MARDI     28/06/2022    10    35    42    47    48      11\n",
       "3  VENDREDI  24/06/2022    10    17    28    44    50      12\n",
       "4  MARDI     21/06/2022     6    23    36    39    47      10\n",
       "5  VENDREDI  17/06/2022    19    21    22    31    38       7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tirage=df_tirage.tail(df_tirage.shape[0])# suppression du dernier tirage/à éviter selon le cas \n",
    "df_tirage.head()# le dernier tirage devient ici celui du 26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traitement  des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_tirage.iloc[::-1]#inversion du dataframe pour placer le dernier tirage en dernière position\n",
    "df = df[['num0', 'num1', 'num2', 'num3', 'num4','chance']]#sélection des numéros à  traiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num0</th>\n",
       "      <th>num1</th>\n",
       "      <th>num2</th>\n",
       "      <th>num3</th>\n",
       "      <th>num4</th>\n",
       "      <th>chance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>31</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>36</td>\n",
       "      <td>39</td>\n",
       "      <td>47</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>28</td>\n",
       "      <td>44</td>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>35</td>\n",
       "      <td>42</td>\n",
       "      <td>47</td>\n",
       "      <td>48</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>34</td>\n",
       "      <td>46</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num0  num1  num2  num3  num4  chance\n",
       "5    19    21    22    31    38       7\n",
       "4     6    23    36    39    47      10\n",
       "3    10    17    28    44    50      12\n",
       "2    10    35    42    47    48      11\n",
       "1     6    18    24    34    46      12"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()# notre tirage du 26 ici devient le dernier de notre dataset afin de pourvoir organiser les data par historique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#fonction de vérification de nombres en dessous d'une certaine valeur pour les 5 premiers numéros, sauf celui de chance\n",
    "def is_under(data, number):\n",
    "    return ((data['num0'] <= number).astype(int) + \n",
    "            (data['num1'] <= number).astype(int) +\n",
    "            (data['num2'] <= number).astype(int) +\n",
    "            (data['num3'] <= number).astype(int) +\n",
    "            (data['num4'] <= number).astype(int))\n",
    "\n",
    "#fonction de vérification de nombres pairs pour les 5 premiers numéros sauf celui de chance\n",
    "def is_pair(data):\n",
    "    return ((data['num0'].isin(pairs)).astype(int) + \n",
    "            (data['num1'].isin(pairs)).astype(int) +\n",
    "            (data['num2'].isin(pairs)).astype(int) +\n",
    "            (data['num3'].isin(pairs)).astype(int) +\n",
    "            (data['num4'].isin(pairs)).astype(int))\n",
    "\n",
    "#fonction de vérification de nombres impairs pour les 5 premiers numéros sauf celui de chance\n",
    "def is_impair(data):\n",
    "    return ((data['num0'].isin(impairs)).astype(int) + \n",
    "            (data['num1'].isin(impairs)).astype(int) +\n",
    "            (data['num2'].isin(impairs)).astype(int) +\n",
    "            (data['num3'].isin(impairs)).astype(int) +\n",
    "            (data['num4'].isin(impairs)).astype(int))\n",
    "\n",
    "#fonction de vérification de nombres pairs pour le numéro de chance\n",
    "def is_pair_etoile(data):\n",
    "    return ((data['chance'].isin(pairs)).astype(int))\n",
    "\n",
    "#fonction de vérification de nombres impairs pour le numéro de chance\n",
    "def is_impair_etoile(data):\n",
    "    return ((data['chance'].isin(impairs)).astype(int))\n",
    "\n",
    "#liste de nombres pairs et impairs\n",
    "pairs = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50]\n",
    "impairs = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]\n",
    "\n",
    "#Fonction de calcul de la somme de la différence au carré des 5 premiers numéros, sauf celui de chance\n",
    "def sum_diff(data):\n",
    "    return ((data['num1'] - data['num0'])**2 + \n",
    "            (data['num2'] - data['num1'])**2 +\n",
    "            (data['num3'] - data['num2'])**2 +\n",
    "            (data['num4'] - data['num3'])**2)\n",
    "\n",
    "# Calcul de la fréquence de tirage de chaque numéro\n",
    "freqs = []\n",
    "for val in range(50):\n",
    "    count = ( (df['num0'] == val+1).sum() +\n",
    "              (df['num1'] == val+1).sum() +\n",
    "              (df['num2'] == val+1).sum() +\n",
    "              (df['num3'] == val+1).sum() +\n",
    "              (df['num4'] == val+1).sum() )\n",
    "    freqs.append(count)\n",
    "ax = plt.gca() ;  ax.invert_yaxis()\n",
    "plt.gcf().set_size_inches(5, 4)\n",
    "heatmap = plt.pcolor(np.reshape(np.array(freqs), (5, 10)), cmap=plt.cm.Blues)\n",
    "\n",
    "def freq_val(data, column):\n",
    "    tab = data[column].values.tolist()\n",
    "    freqs = []\n",
    "    pos = 1\n",
    "    for e in tab:\n",
    "        freqs.append(tab[0:pos].count(e))\n",
    "        pos = pos + 1\n",
    "    return freqs\n",
    "\n",
    "\n",
    "\n",
    "#df['sum'] = ((df.num0 + df.num1 + df.num2 + df.num3 + df.num4 +  df.chance1 ) >199).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num0</th>\n",
       "      <th>num1</th>\n",
       "      <th>num2</th>\n",
       "      <th>num3</th>\n",
       "      <th>num4</th>\n",
       "      <th>chance</th>\n",
       "      <th>freq_num0</th>\n",
       "      <th>freq_num1</th>\n",
       "      <th>freq_num2</th>\n",
       "      <th>freq_num3</th>\n",
       "      <th>freq_num4</th>\n",
       "      <th>freq_chance</th>\n",
       "      <th>sum_diff</th>\n",
       "      <th>pair_chance</th>\n",
       "      <th>impair_chance</th>\n",
       "      <th>pair</th>\n",
       "      <th>impair</th>\n",
       "      <th>is_under_24</th>\n",
       "      <th>is_under_40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>33</td>\n",
       "      <td>35</td>\n",
       "      <td>47</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>252</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>329</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>32</td>\n",
       "      <td>43</td>\n",
       "      <td>46</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>170</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>35</td>\n",
       "      <td>41</td>\n",
       "      <td>49</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>550</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>11</td>\n",
       "      <td>32</td>\n",
       "      <td>34</td>\n",
       "      <td>38</td>\n",
       "      <td>47</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>542</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>478</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     num0  num1  num2  num3  num4  chance  freq_num0  freq_num1  freq_num2  \\\n",
       "252    21    23    33    35    47       6          1          1          1   \n",
       "251     9    15    17    25    40       9          1          1          1   \n",
       "250    24    26    32    43    46       6          1          1          1   \n",
       "249     5    20    35    41    49      10          1          1          1   \n",
       "248    11    32    34    38    47      10          1          1          1   \n",
       "247     7    23    30    32    45       5          1          2          1   \n",
       "\n",
       "     freq_num3  freq_num4  freq_chance  sum_diff  pair_chance  impair_chance  \\\n",
       "252          1          1            1       252            1              0   \n",
       "251          1          1            1       329            0              1   \n",
       "250          1          1            2       170            1              0   \n",
       "249          1          1            1       550            1              0   \n",
       "248          1          2            2       542            1              0   \n",
       "247          1          1            1       478            0              1   \n",
       "\n",
       "     pair  impair  is_under_24  is_under_40  \n",
       "252     0       5            2            4  \n",
       "251     1       4            3            5  \n",
       "250     4       1            1            3  \n",
       "249     1       4            2            3  \n",
       "248     3       2            1            4  \n",
       "247     2       3            2            4  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ajout de la difference entre les numéros(A explorer ASAp)\n",
    "#for i in range(4):\n",
    "#   (i,i+1)\n",
    "#df['diff_{}'.format(i)]=df['num{}'.format(i+1)]-df['num{}'.format(i)]\n",
    "#application des fonctions sur le dataframe\n",
    "df['freq_num0'] = freq_val(df, 'num0')\n",
    "df['freq_num1'] = freq_val(df, 'num1')\n",
    "df['freq_num2'] = freq_val(df, 'num2')\n",
    "df['freq_num3'] = freq_val(df, 'num3')\n",
    "df['freq_num4'] = freq_val(df, 'num4')\n",
    "df['freq_chance'] = freq_val(df, 'chance')#calcul des frequences \n",
    "df['sum_diff'] = sum_diff(df)#somme de la différence au carré entre chaque couple de numéros successifs dans le tirage\n",
    "df['pair_chance'] = is_pair_etoile(df)\n",
    "df['impair_chance'] = is_impair_etoile(df)\n",
    "df['pair'] = is_pair(df)\n",
    "df['impair'] = is_impair(df)#verification de nombre pair et impair\n",
    "df['is_under_24'] = is_under(df, 24)  # Les numeros en dessous de 24 \n",
    "df['is_under_40'] = is_under(df, 40)# Les numeros en dessous de 40 \n",
    "df.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle et fonction de formatage des données en entrée du LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#capture 3: fonction define model seulement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# j'ai ici défini plusieurs modèles à tester mais pour l'intant je tavaille avec le lstm(fonction : define_model)\n",
    "# j'ai ici défini window_length à 12 pour apprendre sur 1 mois de données \n",
    "\n",
    "#Params du modèle\n",
    "nb_label_feature=6\n",
    "\n",
    "UNITS = 200\n",
    "BATCHSIZE = 30\n",
    "EPOCH = 1500\n",
    "# ACTIVATION = \"softmax\"\n",
    "OPTIMIZER ='adam' # rmsprop, adam, sgd\n",
    "LOSS = 'mae'#'categorical_crossentropy' #mse\n",
    "DROPOUT = 0.1\n",
    "window_length =36 #12 \n",
    "number_of_features = df.shape[1]\n",
    "\n",
    "#Architecture du modèle\n",
    "def define_model(number_of_features,nb_label_feature):\n",
    "    #initialisation du rnn\n",
    "    model = Sequential()\n",
    "    #ajout de la premiere couche lstm\n",
    "    model.add(LSTM(UNITS, input_shape=(window_length, number_of_features), return_sequences=True))\n",
    "    model.add(LSTM(UNITS, dropout=0.1, return_sequences=False))\n",
    "    #ajout de la couche de sortie\n",
    "    model.add(Dense(nb_label_feature))\n",
    "    model.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "def define_bidirectionnel_model(number_of_features,nb_label_feature):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(100, dropout=0.2, return_sequences=True), input_shape=(window_length, number_of_features)))\n",
    "    model.add(LSTM(50, return_sequences=True))\n",
    "    model.add(LSTM(100, dropout=0.1))\n",
    "    model.add(Dense(nb_label_feature))\n",
    "    model.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "def define_autoencoder_model(number_of_features,nb_label_feature):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, input_shape=(window_length, number_of_features), return_sequences=True))\n",
    "    model.add(LSTM(50, return_sequences=False))\n",
    "    model.add(RepeatVector(window_length))\n",
    "    model.add(LSTM(100, dropout=0.1, return_sequences=True))\n",
    "    model.add(LSTM(50, return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(number_of_features)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(nb_label_feature))\n",
    "    model.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "#model = define_model(number_of_features,nb_label_feature)\n",
    "#model3 = define_autoencoder_model(number_of_features,nb_label_feature)\n",
    "#model4 = define_bidirectionnel_model(number_of_features,nb_label_feature)\n",
    "\n",
    "#Moniteur pour stoper le training\n",
    "es = EarlyStopping(monitor='acc', mode='max', verbose=1, patience=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de formatage des données en entrée du LSTM\n",
    "def create_lstm_dataset(df, window_length,nb_label_feature):\n",
    "    number_of_rows = df.shape[0]   #taille du dataset number_of_features\n",
    "    number_of_features = df.shape[1]\n",
    "    scaler = StandardScaler().fit(df.values)\n",
    "    transformed_dataset = scaler.transform(df.values)\n",
    "    transformed_df = pd.DataFrame(data=transformed_dataset, index=df.index)\n",
    "    #tableau de tableau de taille(number_of_rows-window_length) et window_length ligne,number_of_features\n",
    "    #lstm:[nb total de row ,nb de ligne dans le passé, nb de colonne(feature)]\n",
    "    train = np.empty([number_of_rows-window_length, window_length, number_of_features], dtype=float)\n",
    "    \n",
    "    label = np.empty([number_of_rows-window_length, nb_label_feature], dtype=float)\n",
    "    for i in range(0, number_of_rows-window_length):\n",
    "        train[i] = transformed_df.iloc[i:i+window_length, 0: number_of_features]\n",
    "        label[i] = transformed_df.iloc[i+window_length: i+window_length+1, 0:nb_label_feature]\n",
    "        \n",
    "    #définition du modèle Lstm  \n",
    "    model = define_model(number_of_features,nb_label_feature)\n",
    "        \n",
    "    return train, label, model,scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(216, 36, 19)\n",
      "(216, 6)\n"
     ]
    }
   ],
   "source": [
    "#formatage des données\n",
    "train, label,model,scaler1 = create_lstm_dataset(df, window_length,nb_label_feature)\n",
    "print(train.shape)\n",
    "print(label.shape)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* On voit ici que notre dataset d'entrainement après formatage est constitué de 1911 vecteurs contenant chacun 12 tirages où chaque tirage contient 19 features calculés plus haut\n",
    "\n",
    "* Quant aux labels, on a bien 1911 vecteurs de 6 features soit les 6 numéros de chaque tirages\n",
    "\n",
    "* Ainsi à partir des 12 tirages précédent on éssaie de prédire le tirage suivant lors de l'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "8/8 - 3s - loss: 0.8242 - acc: 0.1528 - 3s/epoch - 364ms/step\n",
      "Epoch 2/1500\n",
      "8/8 - 0s - loss: 0.7952 - acc: 0.1620 - 381ms/epoch - 48ms/step\n",
      "Epoch 3/1500\n",
      "8/8 - 0s - loss: 0.7834 - acc: 0.2037 - 380ms/epoch - 47ms/step\n",
      "Epoch 4/1500\n",
      "8/8 - 0s - loss: 0.7758 - acc: 0.1806 - 398ms/epoch - 50ms/step\n",
      "Epoch 5/1500\n",
      "8/8 - 0s - loss: 0.7707 - acc: 0.2083 - 402ms/epoch - 50ms/step\n",
      "Epoch 6/1500\n",
      "8/8 - 0s - loss: 0.7625 - acc: 0.2222 - 383ms/epoch - 48ms/step\n",
      "Epoch 7/1500\n",
      "8/8 - 0s - loss: 0.7569 - acc: 0.1898 - 379ms/epoch - 47ms/step\n",
      "Epoch 8/1500\n",
      "8/8 - 0s - loss: 0.7524 - acc: 0.2269 - 379ms/epoch - 47ms/step\n",
      "Epoch 9/1500\n",
      "8/8 - 0s - loss: 0.7617 - acc: 0.1991 - 376ms/epoch - 47ms/step\n",
      "Epoch 10/1500\n",
      "8/8 - 0s - loss: 0.7441 - acc: 0.2222 - 377ms/epoch - 47ms/step\n",
      "Epoch 11/1500\n",
      "8/8 - 0s - loss: 0.7366 - acc: 0.2593 - 398ms/epoch - 50ms/step\n",
      "Epoch 12/1500\n",
      "8/8 - 0s - loss: 0.7243 - acc: 0.2546 - 392ms/epoch - 49ms/step\n",
      "Epoch 13/1500\n",
      "8/8 - 0s - loss: 0.7237 - acc: 0.2593 - 397ms/epoch - 50ms/step\n",
      "Epoch 14/1500\n",
      "8/8 - 0s - loss: 0.7163 - acc: 0.2685 - 411ms/epoch - 51ms/step\n",
      "Epoch 15/1500\n",
      "8/8 - 0s - loss: 0.7120 - acc: 0.3056 - 378ms/epoch - 47ms/step\n",
      "Epoch 16/1500\n",
      "8/8 - 0s - loss: 0.7033 - acc: 0.3519 - 373ms/epoch - 47ms/step\n",
      "Epoch 17/1500\n",
      "8/8 - 0s - loss: 0.6985 - acc: 0.3611 - 378ms/epoch - 47ms/step\n",
      "Epoch 18/1500\n",
      "8/8 - 0s - loss: 0.7113 - acc: 0.3194 - 393ms/epoch - 49ms/step\n",
      "Epoch 19/1500\n",
      "8/8 - 0s - loss: 0.6922 - acc: 0.3426 - 390ms/epoch - 49ms/step\n",
      "Epoch 20/1500\n",
      "8/8 - 0s - loss: 0.6889 - acc: 0.3148 - 376ms/epoch - 47ms/step\n",
      "Epoch 21/1500\n",
      "8/8 - 0s - loss: 0.6822 - acc: 0.3565 - 376ms/epoch - 47ms/step\n",
      "Epoch 22/1500\n",
      "8/8 - 0s - loss: 0.6713 - acc: 0.3565 - 377ms/epoch - 47ms/step\n",
      "Epoch 23/1500\n",
      "8/8 - 0s - loss: 0.6713 - acc: 0.3194 - 380ms/epoch - 48ms/step\n",
      "Epoch 24/1500\n",
      "8/8 - 0s - loss: 0.6649 - acc: 0.3611 - 392ms/epoch - 49ms/step\n",
      "Epoch 25/1500\n",
      "8/8 - 0s - loss: 0.6592 - acc: 0.3750 - 374ms/epoch - 47ms/step\n",
      "Epoch 26/1500\n",
      "8/8 - 0s - loss: 0.6543 - acc: 0.3935 - 413ms/epoch - 52ms/step\n",
      "Epoch 27/1500\n",
      "8/8 - 0s - loss: 0.6462 - acc: 0.3843 - 379ms/epoch - 47ms/step\n",
      "Epoch 28/1500\n",
      "8/8 - 0s - loss: 0.6407 - acc: 0.3981 - 379ms/epoch - 47ms/step\n",
      "Epoch 29/1500\n",
      "8/8 - 0s - loss: 0.6253 - acc: 0.3843 - 376ms/epoch - 47ms/step\n",
      "Epoch 30/1500\n",
      "8/8 - 0s - loss: 0.6249 - acc: 0.4074 - 407ms/epoch - 51ms/step\n",
      "Epoch 31/1500\n",
      "8/8 - 0s - loss: 0.6209 - acc: 0.4120 - 397ms/epoch - 50ms/step\n",
      "Epoch 32/1500\n",
      "8/8 - 0s - loss: 0.6118 - acc: 0.4259 - 382ms/epoch - 48ms/step\n",
      "Epoch 33/1500\n",
      "8/8 - 0s - loss: 0.5963 - acc: 0.4722 - 396ms/epoch - 50ms/step\n",
      "Epoch 34/1500\n",
      "8/8 - 0s - loss: 0.6037 - acc: 0.4583 - 376ms/epoch - 47ms/step\n",
      "Epoch 35/1500\n",
      "8/8 - 0s - loss: 0.5871 - acc: 0.4491 - 377ms/epoch - 47ms/step\n",
      "Epoch 36/1500\n",
      "8/8 - 0s - loss: 0.5769 - acc: 0.4630 - 384ms/epoch - 48ms/step\n",
      "Epoch 37/1500\n",
      "8/8 - 0s - loss: 0.5733 - acc: 0.4722 - 392ms/epoch - 49ms/step\n",
      "Epoch 38/1500\n",
      "8/8 - 0s - loss: 0.5815 - acc: 0.4537 - 388ms/epoch - 48ms/step\n",
      "Epoch 39/1500\n",
      "8/8 - 0s - loss: 0.5698 - acc: 0.4352 - 379ms/epoch - 47ms/step\n",
      "Epoch 40/1500\n",
      "8/8 - 0s - loss: 0.5640 - acc: 0.4120 - 424ms/epoch - 53ms/step\n",
      "Epoch 41/1500\n",
      "8/8 - 0s - loss: 0.5536 - acc: 0.4306 - 385ms/epoch - 48ms/step\n",
      "Epoch 42/1500\n",
      "8/8 - 0s - loss: 0.5554 - acc: 0.4954 - 389ms/epoch - 49ms/step\n",
      "Epoch 43/1500\n",
      "8/8 - 0s - loss: 0.5520 - acc: 0.4630 - 381ms/epoch - 48ms/step\n",
      "Epoch 44/1500\n",
      "8/8 - 0s - loss: 0.5429 - acc: 0.5046 - 378ms/epoch - 47ms/step\n",
      "Epoch 45/1500\n",
      "8/8 - 0s - loss: 0.5149 - acc: 0.4815 - 377ms/epoch - 47ms/step\n",
      "Epoch 46/1500\n",
      "8/8 - 0s - loss: 0.5105 - acc: 0.4861 - 378ms/epoch - 47ms/step\n",
      "Epoch 47/1500\n",
      "8/8 - 0s - loss: 0.4994 - acc: 0.5093 - 378ms/epoch - 47ms/step\n",
      "Epoch 48/1500\n",
      "8/8 - 0s - loss: 0.4947 - acc: 0.4815 - 379ms/epoch - 47ms/step\n",
      "Epoch 49/1500\n",
      "8/8 - 0s - loss: 0.4889 - acc: 0.4907 - 379ms/epoch - 47ms/step\n",
      "Epoch 50/1500\n",
      "8/8 - 0s - loss: 0.4649 - acc: 0.5185 - 392ms/epoch - 49ms/step\n",
      "Epoch 51/1500\n",
      "8/8 - 0s - loss: 0.4672 - acc: 0.5000 - 463ms/epoch - 58ms/step\n",
      "Epoch 52/1500\n",
      "8/8 - 0s - loss: 0.4562 - acc: 0.5185 - 379ms/epoch - 47ms/step\n",
      "Epoch 53/1500\n",
      "8/8 - 0s - loss: 0.4462 - acc: 0.5093 - 379ms/epoch - 47ms/step\n",
      "Epoch 54/1500\n",
      "8/8 - 0s - loss: 0.4465 - acc: 0.5278 - 392ms/epoch - 49ms/step\n",
      "Epoch 55/1500\n",
      "8/8 - 0s - loss: 0.4332 - acc: 0.5185 - 380ms/epoch - 48ms/step\n",
      "Epoch 56/1500\n",
      "8/8 - 0s - loss: 0.4311 - acc: 0.5648 - 380ms/epoch - 47ms/step\n",
      "Epoch 57/1500\n",
      "8/8 - 0s - loss: 0.4236 - acc: 0.5417 - 394ms/epoch - 49ms/step\n",
      "Epoch 58/1500\n",
      "8/8 - 0s - loss: 0.4156 - acc: 0.5046 - 378ms/epoch - 47ms/step\n",
      "Epoch 59/1500\n",
      "8/8 - 0s - loss: 0.4102 - acc: 0.5694 - 383ms/epoch - 48ms/step\n",
      "Epoch 60/1500\n",
      "8/8 - 0s - loss: 0.3985 - acc: 0.5278 - 379ms/epoch - 47ms/step\n",
      "Epoch 61/1500\n",
      "8/8 - 0s - loss: 0.3873 - acc: 0.5926 - 400ms/epoch - 50ms/step\n",
      "Epoch 62/1500\n",
      "8/8 - 0s - loss: 0.3775 - acc: 0.5602 - 382ms/epoch - 48ms/step\n",
      "Epoch 63/1500\n",
      "8/8 - 0s - loss: 0.3648 - acc: 0.5556 - 379ms/epoch - 47ms/step\n",
      "Epoch 64/1500\n",
      "8/8 - 0s - loss: 0.3576 - acc: 0.5787 - 382ms/epoch - 48ms/step\n",
      "Epoch 65/1500\n",
      "8/8 - 0s - loss: 0.3651 - acc: 0.5833 - 381ms/epoch - 48ms/step\n",
      "Epoch 66/1500\n",
      "8/8 - 0s - loss: 0.3545 - acc: 0.6343 - 387ms/epoch - 48ms/step\n",
      "Epoch 67/1500\n",
      "8/8 - 0s - loss: 0.3392 - acc: 0.6343 - 381ms/epoch - 48ms/step\n",
      "Epoch 68/1500\n",
      "8/8 - 0s - loss: 0.3388 - acc: 0.6296 - 384ms/epoch - 48ms/step\n",
      "Epoch 69/1500\n",
      "8/8 - 0s - loss: 0.3480 - acc: 0.6157 - 381ms/epoch - 48ms/step\n",
      "Epoch 70/1500\n",
      "8/8 - 0s - loss: 0.3354 - acc: 0.6204 - 381ms/epoch - 48ms/step\n",
      "Epoch 71/1500\n",
      "8/8 - 0s - loss: 0.3170 - acc: 0.6435 - 380ms/epoch - 47ms/step\n",
      "Epoch 72/1500\n",
      "8/8 - 0s - loss: 0.3055 - acc: 0.6343 - 382ms/epoch - 48ms/step\n",
      "Epoch 73/1500\n",
      "8/8 - 0s - loss: 0.2968 - acc: 0.6574 - 379ms/epoch - 47ms/step\n",
      "Epoch 74/1500\n",
      "8/8 - 0s - loss: 0.2937 - acc: 0.6343 - 405ms/epoch - 51ms/step\n",
      "Epoch 75/1500\n",
      "8/8 - 0s - loss: 0.2861 - acc: 0.6435 - 436ms/epoch - 55ms/step\n",
      "Epoch 76/1500\n",
      "8/8 - 0s - loss: 0.2818 - acc: 0.7083 - 375ms/epoch - 47ms/step\n",
      "Epoch 77/1500\n",
      "8/8 - 0s - loss: 0.2836 - acc: 0.6528 - 378ms/epoch - 47ms/step\n",
      "Epoch 78/1500\n",
      "8/8 - 0s - loss: 0.2664 - acc: 0.7454 - 378ms/epoch - 47ms/step\n",
      "Epoch 79/1500\n",
      "8/8 - 0s - loss: 0.2673 - acc: 0.7407 - 379ms/epoch - 47ms/step\n",
      "Epoch 80/1500\n",
      "8/8 - 0s - loss: 0.2468 - acc: 0.7269 - 380ms/epoch - 48ms/step\n",
      "Epoch 81/1500\n",
      "8/8 - 0s - loss: 0.2461 - acc: 0.7176 - 379ms/epoch - 47ms/step\n",
      "Epoch 82/1500\n",
      "8/8 - 0s - loss: 0.2318 - acc: 0.7269 - 378ms/epoch - 47ms/step\n",
      "Epoch 83/1500\n",
      "8/8 - 0s - loss: 0.2317 - acc: 0.7870 - 394ms/epoch - 49ms/step\n",
      "Epoch 84/1500\n",
      "8/8 - 0s - loss: 0.2200 - acc: 0.7500 - 377ms/epoch - 47ms/step\n",
      "Epoch 85/1500\n",
      "8/8 - 0s - loss: 0.2296 - acc: 0.7176 - 380ms/epoch - 47ms/step\n",
      "Epoch 86/1500\n",
      "8/8 - 0s - loss: 0.2174 - acc: 0.7454 - 375ms/epoch - 47ms/step\n",
      "Epoch 87/1500\n",
      "8/8 - 0s - loss: 0.2142 - acc: 0.8009 - 376ms/epoch - 47ms/step\n",
      "Epoch 88/1500\n",
      "8/8 - 0s - loss: 0.2153 - acc: 0.7593 - 389ms/epoch - 49ms/step\n",
      "Epoch 89/1500\n",
      "8/8 - 0s - loss: 0.2087 - acc: 0.7500 - 418ms/epoch - 52ms/step\n",
      "Epoch 90/1500\n",
      "8/8 - 0s - loss: 0.2067 - acc: 0.8056 - 466ms/epoch - 58ms/step\n",
      "Epoch 91/1500\n",
      "8/8 - 0s - loss: 0.2077 - acc: 0.7917 - 482ms/epoch - 60ms/step\n",
      "Epoch 92/1500\n",
      "8/8 - 0s - loss: 0.1908 - acc: 0.7685 - 492ms/epoch - 61ms/step\n",
      "Epoch 93/1500\n",
      "8/8 - 0s - loss: 0.1966 - acc: 0.7963 - 440ms/epoch - 55ms/step\n",
      "Epoch 94/1500\n",
      "8/8 - 0s - loss: 0.1989 - acc: 0.7870 - 408ms/epoch - 51ms/step\n",
      "Epoch 95/1500\n",
      "8/8 - 0s - loss: 0.1930 - acc: 0.7917 - 432ms/epoch - 54ms/step\n",
      "Epoch 96/1500\n",
      "8/8 - 0s - loss: 0.1971 - acc: 0.7917 - 413ms/epoch - 52ms/step\n",
      "Epoch 97/1500\n",
      "8/8 - 0s - loss: 0.1864 - acc: 0.8148 - 440ms/epoch - 55ms/step\n",
      "Epoch 98/1500\n",
      "8/8 - 0s - loss: 0.1851 - acc: 0.8194 - 421ms/epoch - 53ms/step\n",
      "Epoch 99/1500\n",
      "8/8 - 0s - loss: 0.1693 - acc: 0.8194 - 432ms/epoch - 54ms/step\n",
      "Epoch 100/1500\n",
      "8/8 - 0s - loss: 0.1693 - acc: 0.8056 - 421ms/epoch - 53ms/step\n",
      "Epoch 101/1500\n",
      "8/8 - 0s - loss: 0.1663 - acc: 0.8148 - 448ms/epoch - 56ms/step\n",
      "Epoch 102/1500\n",
      "8/8 - 0s - loss: 0.1642 - acc: 0.8333 - 395ms/epoch - 49ms/step\n",
      "Epoch 103/1500\n",
      "8/8 - 0s - loss: 0.1601 - acc: 0.8472 - 435ms/epoch - 54ms/step\n",
      "Epoch 104/1500\n",
      "8/8 - 0s - loss: 0.1533 - acc: 0.8241 - 398ms/epoch - 50ms/step\n",
      "Epoch 105/1500\n",
      "8/8 - 0s - loss: 0.1482 - acc: 0.8380 - 423ms/epoch - 53ms/step\n",
      "Epoch 106/1500\n",
      "8/8 - 0s - loss: 0.1509 - acc: 0.8102 - 423ms/epoch - 53ms/step\n",
      "Epoch 107/1500\n",
      "8/8 - 0s - loss: 0.1515 - acc: 0.8287 - 442ms/epoch - 55ms/step\n",
      "Epoch 108/1500\n",
      "8/8 - 0s - loss: 0.1449 - acc: 0.8380 - 399ms/epoch - 50ms/step\n",
      "Epoch 109/1500\n",
      "8/8 - 0s - loss: 0.1392 - acc: 0.8472 - 433ms/epoch - 54ms/step\n",
      "Epoch 110/1500\n",
      "8/8 - 1s - loss: 0.1431 - acc: 0.8565 - 505ms/epoch - 63ms/step\n",
      "Epoch 111/1500\n",
      "8/8 - 0s - loss: 0.1481 - acc: 0.8426 - 440ms/epoch - 55ms/step\n",
      "Epoch 112/1500\n",
      "8/8 - 0s - loss: 0.1313 - acc: 0.8426 - 470ms/epoch - 59ms/step\n",
      "Epoch 113/1500\n",
      "8/8 - 1s - loss: 0.1318 - acc: 0.8611 - 538ms/epoch - 67ms/step\n",
      "Epoch 114/1500\n",
      "8/8 - 0s - loss: 0.1342 - acc: 0.8565 - 444ms/epoch - 55ms/step\n",
      "Epoch 115/1500\n",
      "8/8 - 0s - loss: 0.1248 - acc: 0.8380 - 432ms/epoch - 54ms/step\n",
      "Epoch 116/1500\n",
      "8/8 - 0s - loss: 0.1222 - acc: 0.8750 - 384ms/epoch - 48ms/step\n",
      "Epoch 117/1500\n",
      "8/8 - 0s - loss: 0.1252 - acc: 0.8935 - 386ms/epoch - 48ms/step\n",
      "Epoch 118/1500\n",
      "8/8 - 0s - loss: 0.1342 - acc: 0.8565 - 388ms/epoch - 48ms/step\n",
      "Epoch 119/1500\n",
      "8/8 - 0s - loss: 0.1261 - acc: 0.8889 - 389ms/epoch - 49ms/step\n",
      "Epoch 120/1500\n",
      "8/8 - 0s - loss: 0.1173 - acc: 0.8843 - 383ms/epoch - 48ms/step\n",
      "Epoch 121/1500\n",
      "8/8 - 0s - loss: 0.1136 - acc: 0.8796 - 381ms/epoch - 48ms/step\n",
      "Epoch 122/1500\n",
      "8/8 - 0s - loss: 0.1155 - acc: 0.8796 - 376ms/epoch - 47ms/step\n",
      "Epoch 123/1500\n",
      "8/8 - 0s - loss: 0.1177 - acc: 0.8611 - 373ms/epoch - 47ms/step\n",
      "Epoch 124/1500\n",
      "8/8 - 0s - loss: 0.1208 - acc: 0.8657 - 379ms/epoch - 47ms/step\n",
      "Epoch 125/1500\n",
      "8/8 - 0s - loss: 0.1228 - acc: 0.8889 - 380ms/epoch - 47ms/step\n",
      "Epoch 126/1500\n",
      "8/8 - 0s - loss: 0.1204 - acc: 0.8935 - 375ms/epoch - 47ms/step\n",
      "Epoch 127/1500\n",
      "8/8 - 0s - loss: 0.1174 - acc: 0.9074 - 406ms/epoch - 51ms/step\n",
      "Epoch 128/1500\n",
      "8/8 - 0s - loss: 0.1208 - acc: 0.8935 - 382ms/epoch - 48ms/step\n",
      "Epoch 129/1500\n",
      "8/8 - 0s - loss: 0.1130 - acc: 0.8843 - 382ms/epoch - 48ms/step\n",
      "Epoch 130/1500\n",
      "8/8 - 0s - loss: 0.1101 - acc: 0.8843 - 381ms/epoch - 48ms/step\n",
      "Epoch 131/1500\n",
      "8/8 - 0s - loss: 0.1121 - acc: 0.8796 - 389ms/epoch - 49ms/step\n",
      "Epoch 132/1500\n",
      "8/8 - 0s - loss: 0.1064 - acc: 0.8935 - 377ms/epoch - 47ms/step\n",
      "Epoch 133/1500\n",
      "8/8 - 0s - loss: 0.1061 - acc: 0.8935 - 378ms/epoch - 47ms/step\n",
      "Epoch 134/1500\n",
      "8/8 - 0s - loss: 0.0984 - acc: 0.9213 - 376ms/epoch - 47ms/step\n",
      "Epoch 135/1500\n",
      "8/8 - 0s - loss: 0.1022 - acc: 0.8889 - 375ms/epoch - 47ms/step\n",
      "Epoch 136/1500\n",
      "8/8 - 0s - loss: 0.1088 - acc: 0.8981 - 380ms/epoch - 47ms/step\n",
      "Epoch 137/1500\n",
      "8/8 - 0s - loss: 0.1044 - acc: 0.8472 - 373ms/epoch - 47ms/step\n",
      "Epoch 138/1500\n",
      "8/8 - 0s - loss: 0.1052 - acc: 0.8981 - 381ms/epoch - 48ms/step\n",
      "Epoch 139/1500\n",
      "8/8 - 0s - loss: 0.1087 - acc: 0.8935 - 389ms/epoch - 49ms/step\n",
      "Epoch 140/1500\n",
      "8/8 - 0s - loss: 0.1051 - acc: 0.9028 - 378ms/epoch - 47ms/step\n",
      "Epoch 141/1500\n",
      "8/8 - 0s - loss: 0.1030 - acc: 0.9167 - 377ms/epoch - 47ms/step\n",
      "Epoch 142/1500\n",
      "8/8 - 0s - loss: 0.0976 - acc: 0.9120 - 374ms/epoch - 47ms/step\n",
      "Epoch 143/1500\n",
      "8/8 - 0s - loss: 0.0957 - acc: 0.9167 - 378ms/epoch - 47ms/step\n",
      "Epoch 144/1500\n",
      "8/8 - 0s - loss: 0.0929 - acc: 0.9167 - 417ms/epoch - 52ms/step\n",
      "Epoch 145/1500\n",
      "8/8 - 0s - loss: 0.0941 - acc: 0.8796 - 382ms/epoch - 48ms/step\n",
      "Epoch 146/1500\n",
      "8/8 - 0s - loss: 0.0982 - acc: 0.9167 - 376ms/epoch - 47ms/step\n",
      "Epoch 147/1500\n",
      "8/8 - 0s - loss: 0.0938 - acc: 0.8889 - 380ms/epoch - 47ms/step\n",
      "Epoch 148/1500\n",
      "8/8 - 0s - loss: 0.0970 - acc: 0.9120 - 376ms/epoch - 47ms/step\n",
      "Epoch 149/1500\n",
      "8/8 - 0s - loss: 0.0916 - acc: 0.9491 - 375ms/epoch - 47ms/step\n",
      "Epoch 150/1500\n",
      "8/8 - 0s - loss: 0.0938 - acc: 0.9444 - 374ms/epoch - 47ms/step\n",
      "Epoch 151/1500\n",
      "8/8 - 0s - loss: 0.0956 - acc: 0.9352 - 384ms/epoch - 48ms/step\n",
      "Epoch 152/1500\n",
      "8/8 - 0s - loss: 0.0957 - acc: 0.8935 - 374ms/epoch - 47ms/step\n",
      "Epoch 153/1500\n",
      "8/8 - 0s - loss: 0.0974 - acc: 0.8981 - 378ms/epoch - 47ms/step\n",
      "Epoch 154/1500\n",
      "8/8 - 0s - loss: 0.0897 - acc: 0.9352 - 376ms/epoch - 47ms/step\n",
      "Epoch 155/1500\n",
      "8/8 - 0s - loss: 0.0871 - acc: 0.9352 - 372ms/epoch - 47ms/step\n",
      "Epoch 156/1500\n",
      "8/8 - 0s - loss: 0.0910 - acc: 0.8981 - 374ms/epoch - 47ms/step\n",
      "Epoch 157/1500\n",
      "8/8 - 0s - loss: 0.0937 - acc: 0.9213 - 379ms/epoch - 47ms/step\n",
      "Epoch 158/1500\n",
      "8/8 - 0s - loss: 0.0938 - acc: 0.9352 - 377ms/epoch - 47ms/step\n",
      "Epoch 159/1500\n",
      "8/8 - 0s - loss: 0.0878 - acc: 0.9537 - 377ms/epoch - 47ms/step\n",
      "Epoch 160/1500\n",
      "8/8 - 0s - loss: 0.0915 - acc: 0.9259 - 379ms/epoch - 47ms/step\n",
      "Epoch 161/1500\n",
      "8/8 - 0s - loss: 0.0849 - acc: 0.9352 - 412ms/epoch - 51ms/step\n",
      "Epoch 162/1500\n",
      "8/8 - 0s - loss: 0.0859 - acc: 0.9398 - 379ms/epoch - 47ms/step\n",
      "Epoch 163/1500\n",
      "8/8 - 0s - loss: 0.0837 - acc: 0.9259 - 373ms/epoch - 47ms/step\n",
      "Epoch 164/1500\n",
      "8/8 - 0s - loss: 0.0881 - acc: 0.9444 - 380ms/epoch - 47ms/step\n",
      "Epoch 165/1500\n",
      "8/8 - 0s - loss: 0.0852 - acc: 0.9120 - 375ms/epoch - 47ms/step\n",
      "Epoch 166/1500\n",
      "8/8 - 0s - loss: 0.0857 - acc: 0.9120 - 415ms/epoch - 52ms/step\n",
      "Epoch 167/1500\n",
      "8/8 - 0s - loss: 0.0849 - acc: 0.9120 - 410ms/epoch - 51ms/step\n",
      "Epoch 168/1500\n",
      "8/8 - 0s - loss: 0.0844 - acc: 0.9398 - 374ms/epoch - 47ms/step\n",
      "Epoch 169/1500\n",
      "8/8 - 0s - loss: 0.0842 - acc: 0.9352 - 377ms/epoch - 47ms/step\n",
      "Epoch 170/1500\n",
      "8/8 - 0s - loss: 0.0804 - acc: 0.9120 - 378ms/epoch - 47ms/step\n",
      "Epoch 171/1500\n",
      "8/8 - 0s - loss: 0.0785 - acc: 0.9306 - 372ms/epoch - 47ms/step\n",
      "Epoch 172/1500\n",
      "8/8 - 0s - loss: 0.0832 - acc: 0.9074 - 374ms/epoch - 47ms/step\n",
      "Epoch 173/1500\n",
      "8/8 - 0s - loss: 0.0854 - acc: 0.9213 - 377ms/epoch - 47ms/step\n",
      "Epoch 174/1500\n",
      "8/8 - 0s - loss: 0.0820 - acc: 0.9028 - 374ms/epoch - 47ms/step\n",
      "Epoch 175/1500\n",
      "8/8 - 0s - loss: 0.0805 - acc: 0.9352 - 382ms/epoch - 48ms/step\n",
      "Epoch 176/1500\n",
      "8/8 - 0s - loss: 0.0812 - acc: 0.9398 - 378ms/epoch - 47ms/step\n",
      "Epoch 177/1500\n",
      "8/8 - 0s - loss: 0.0780 - acc: 0.9167 - 372ms/epoch - 47ms/step\n",
      "Epoch 178/1500\n",
      "8/8 - 0s - loss: 0.0790 - acc: 0.9259 - 376ms/epoch - 47ms/step\n",
      "Epoch 179/1500\n",
      "8/8 - 0s - loss: 0.0814 - acc: 0.9213 - 373ms/epoch - 47ms/step\n",
      "Epoch 180/1500\n",
      "8/8 - 0s - loss: 0.0827 - acc: 0.9352 - 374ms/epoch - 47ms/step\n",
      "Epoch 181/1500\n",
      "8/8 - 0s - loss: 0.0820 - acc: 0.9167 - 380ms/epoch - 47ms/step\n",
      "Epoch 182/1500\n",
      "8/8 - 0s - loss: 0.0781 - acc: 0.9491 - 372ms/epoch - 47ms/step\n",
      "Epoch 183/1500\n",
      "8/8 - 0s - loss: 0.0756 - acc: 0.9398 - 379ms/epoch - 47ms/step\n",
      "Epoch 184/1500\n",
      "8/8 - 0s - loss: 0.0791 - acc: 0.9444 - 373ms/epoch - 47ms/step\n",
      "Epoch 185/1500\n",
      "8/8 - 0s - loss: 0.0785 - acc: 0.9028 - 374ms/epoch - 47ms/step\n",
      "Epoch 186/1500\n",
      "8/8 - 0s - loss: 0.0763 - acc: 0.9213 - 417ms/epoch - 52ms/step\n",
      "Epoch 187/1500\n",
      "8/8 - 0s - loss: 0.0782 - acc: 0.9352 - 451ms/epoch - 56ms/step\n",
      "Epoch 188/1500\n",
      "8/8 - 0s - loss: 0.0727 - acc: 0.9630 - 382ms/epoch - 48ms/step\n",
      "Epoch 189/1500\n",
      "8/8 - 0s - loss: 0.0777 - acc: 0.9167 - 377ms/epoch - 47ms/step\n",
      "Epoch 190/1500\n",
      "8/8 - 0s - loss: 0.0724 - acc: 0.9213 - 446ms/epoch - 56ms/step\n",
      "Epoch 191/1500\n",
      "8/8 - 0s - loss: 0.0732 - acc: 0.9167 - 486ms/epoch - 61ms/step\n",
      "Epoch 192/1500\n",
      "8/8 - 1s - loss: 0.0730 - acc: 0.9352 - 506ms/epoch - 63ms/step\n",
      "Epoch 193/1500\n",
      "8/8 - 0s - loss: 0.0754 - acc: 0.9352 - 457ms/epoch - 57ms/step\n",
      "Epoch 194/1500\n",
      "8/8 - 0s - loss: 0.0784 - acc: 0.9398 - 441ms/epoch - 55ms/step\n",
      "Epoch 195/1500\n",
      "8/8 - 0s - loss: 0.0771 - acc: 0.9352 - 412ms/epoch - 51ms/step\n",
      "Epoch 196/1500\n",
      "8/8 - 0s - loss: 0.0796 - acc: 0.9398 - 451ms/epoch - 56ms/step\n",
      "Epoch 197/1500\n",
      "8/8 - 1s - loss: 0.0767 - acc: 0.9537 - 514ms/epoch - 64ms/step\n",
      "Epoch 198/1500\n",
      "8/8 - 1s - loss: 0.0743 - acc: 0.9398 - 585ms/epoch - 73ms/step\n",
      "Epoch 199/1500\n",
      "8/8 - 1s - loss: 0.0839 - acc: 0.9259 - 535ms/epoch - 67ms/step\n",
      "Epoch 200/1500\n",
      "8/8 - 0s - loss: 0.0805 - acc: 0.9167 - 491ms/epoch - 61ms/step\n",
      "Epoch 201/1500\n",
      "8/8 - 1s - loss: 0.0777 - acc: 0.9352 - 506ms/epoch - 63ms/step\n",
      "Epoch 202/1500\n",
      "8/8 - 1s - loss: 0.0776 - acc: 0.9398 - 555ms/epoch - 69ms/step\n",
      "Epoch 203/1500\n",
      "8/8 - 1s - loss: 0.0771 - acc: 0.9120 - 501ms/epoch - 63ms/step\n",
      "Epoch 204/1500\n",
      "8/8 - 0s - loss: 0.0743 - acc: 0.9398 - 478ms/epoch - 60ms/step\n",
      "Epoch 205/1500\n",
      "8/8 - 1s - loss: 0.0781 - acc: 0.9491 - 551ms/epoch - 69ms/step\n",
      "Epoch 206/1500\n",
      "8/8 - 1s - loss: 0.0723 - acc: 0.9352 - 617ms/epoch - 77ms/step\n",
      "Epoch 207/1500\n",
      "8/8 - 1s - loss: 0.0726 - acc: 0.9444 - 517ms/epoch - 65ms/step\n",
      "Epoch 208/1500\n",
      "8/8 - 0s - loss: 0.0750 - acc: 0.9398 - 496ms/epoch - 62ms/step\n",
      "Epoch 209/1500\n",
      "8/8 - 1s - loss: 0.0705 - acc: 0.9213 - 545ms/epoch - 68ms/step\n",
      "Epoch 210/1500\n",
      "8/8 - 0s - loss: 0.0734 - acc: 0.9120 - 481ms/epoch - 60ms/step\n",
      "Epoch 211/1500\n",
      "8/8 - 0s - loss: 0.0666 - acc: 0.9306 - 478ms/epoch - 60ms/step\n",
      "Epoch 212/1500\n",
      "8/8 - 0s - loss: 0.0717 - acc: 0.9491 - 473ms/epoch - 59ms/step\n",
      "Epoch 213/1500\n",
      "8/8 - 1s - loss: 0.0675 - acc: 0.9306 - 511ms/epoch - 64ms/step\n",
      "Epoch 214/1500\n",
      "8/8 - 0s - loss: 0.0709 - acc: 0.9352 - 474ms/epoch - 59ms/step\n",
      "Epoch 215/1500\n",
      "8/8 - 1s - loss: 0.0660 - acc: 0.9213 - 508ms/epoch - 63ms/step\n",
      "Epoch 216/1500\n",
      "8/8 - 0s - loss: 0.0677 - acc: 0.9352 - 486ms/epoch - 61ms/step\n",
      "Epoch 217/1500\n",
      "8/8 - 1s - loss: 0.0670 - acc: 0.9120 - 519ms/epoch - 65ms/step\n",
      "Epoch 218/1500\n",
      "8/8 - 0s - loss: 0.0713 - acc: 0.9213 - 490ms/epoch - 61ms/step\n",
      "Epoch 219/1500\n",
      "8/8 - 0s - loss: 0.0697 - acc: 0.9583 - 499ms/epoch - 62ms/step\n",
      "Epoch 220/1500\n",
      "8/8 - 0s - loss: 0.0712 - acc: 0.9491 - 500ms/epoch - 62ms/step\n",
      "Epoch 221/1500\n",
      "8/8 - 0s - loss: 0.0705 - acc: 0.9537 - 492ms/epoch - 61ms/step\n",
      "Epoch 222/1500\n",
      "8/8 - 1s - loss: 0.0682 - acc: 0.9491 - 517ms/epoch - 65ms/step\n",
      "Epoch 223/1500\n",
      "8/8 - 1s - loss: 0.0676 - acc: 0.9306 - 517ms/epoch - 65ms/step\n",
      "Epoch 224/1500\n",
      "8/8 - 0s - loss: 0.0654 - acc: 0.9352 - 499ms/epoch - 62ms/step\n",
      "Epoch 225/1500\n",
      "8/8 - 1s - loss: 0.0674 - acc: 0.9306 - 502ms/epoch - 63ms/step\n",
      "Epoch 226/1500\n",
      "8/8 - 1s - loss: 0.0671 - acc: 0.9444 - 508ms/epoch - 63ms/step\n",
      "Epoch 227/1500\n",
      "8/8 - 0s - loss: 0.0762 - acc: 0.9398 - 499ms/epoch - 62ms/step\n",
      "Epoch 228/1500\n",
      "8/8 - 1s - loss: 0.0742 - acc: 0.9444 - 538ms/epoch - 67ms/step\n",
      "Epoch 229/1500\n",
      "8/8 - 1s - loss: 0.0731 - acc: 0.9306 - 508ms/epoch - 64ms/step\n",
      "Epoch 230/1500\n",
      "8/8 - 1s - loss: 0.0665 - acc: 0.9444 - 509ms/epoch - 64ms/step\n",
      "Epoch 231/1500\n",
      "8/8 - 0s - loss: 0.0702 - acc: 0.9398 - 495ms/epoch - 62ms/step\n",
      "Epoch 232/1500\n",
      "8/8 - 0s - loss: 0.0649 - acc: 0.9213 - 479ms/epoch - 60ms/step\n",
      "Epoch 233/1500\n",
      "8/8 - 0s - loss: 0.0641 - acc: 0.9167 - 493ms/epoch - 62ms/step\n",
      "Epoch 234/1500\n",
      "8/8 - 0s - loss: 0.0676 - acc: 0.9444 - 495ms/epoch - 62ms/step\n",
      "Epoch 235/1500\n",
      "8/8 - 1s - loss: 0.0688 - acc: 0.9491 - 501ms/epoch - 63ms/step\n",
      "Epoch 236/1500\n",
      "8/8 - 1s - loss: 0.0672 - acc: 0.9352 - 513ms/epoch - 64ms/step\n",
      "Epoch 237/1500\n",
      "8/8 - 1s - loss: 0.0707 - acc: 0.9352 - 552ms/epoch - 69ms/step\n",
      "Epoch 238/1500\n",
      "8/8 - 0s - loss: 0.0668 - acc: 0.9259 - 488ms/epoch - 61ms/step\n",
      "Epoch 239/1500\n",
      "8/8 - 0s - loss: 0.0679 - acc: 0.9491 - 499ms/epoch - 62ms/step\n",
      "Epoch 240/1500\n",
      "8/8 - 0s - loss: 0.0693 - acc: 0.9398 - 500ms/epoch - 62ms/step\n",
      "Epoch 241/1500\n",
      "8/8 - 0s - loss: 0.0644 - acc: 0.9444 - 486ms/epoch - 61ms/step\n",
      "Epoch 242/1500\n",
      "8/8 - 1s - loss: 0.0633 - acc: 0.9444 - 505ms/epoch - 63ms/step\n",
      "Epoch 243/1500\n",
      "8/8 - 0s - loss: 0.0648 - acc: 0.9306 - 495ms/epoch - 62ms/step\n",
      "Epoch 244/1500\n",
      "8/8 - 0s - loss: 0.0661 - acc: 0.9491 - 498ms/epoch - 62ms/step\n",
      "Epoch 245/1500\n",
      "8/8 - 1s - loss: 0.0670 - acc: 0.9259 - 550ms/epoch - 69ms/step\n",
      "Epoch 246/1500\n",
      "8/8 - 1s - loss: 0.0666 - acc: 0.9352 - 566ms/epoch - 71ms/step\n",
      "Epoch 247/1500\n",
      "8/8 - 1s - loss: 0.0635 - acc: 0.9398 - 525ms/epoch - 66ms/step\n",
      "Epoch 248/1500\n",
      "8/8 - 0s - loss: 0.0675 - acc: 0.9444 - 495ms/epoch - 62ms/step\n",
      "Epoch 249/1500\n",
      "8/8 - 1s - loss: 0.0649 - acc: 0.9583 - 688ms/epoch - 86ms/step\n",
      "Epoch 250/1500\n",
      "8/8 - 1s - loss: 0.0702 - acc: 0.9630 - 555ms/epoch - 69ms/step\n",
      "Epoch 251/1500\n",
      "8/8 - 0s - loss: 0.0688 - acc: 0.9259 - 481ms/epoch - 60ms/step\n",
      "Epoch 252/1500\n",
      "8/8 - 0s - loss: 0.0661 - acc: 0.9444 - 494ms/epoch - 62ms/step\n",
      "Epoch 253/1500\n",
      "8/8 - 1s - loss: 0.0645 - acc: 0.9259 - 500ms/epoch - 63ms/step\n",
      "Epoch 254/1500\n",
      "8/8 - 0s - loss: 0.0655 - acc: 0.9306 - 488ms/epoch - 61ms/step\n",
      "Epoch 255/1500\n",
      "8/8 - 0s - loss: 0.0637 - acc: 0.9352 - 481ms/epoch - 60ms/step\n",
      "Epoch 256/1500\n",
      "8/8 - 1s - loss: 0.0622 - acc: 0.9676 - 526ms/epoch - 66ms/step\n",
      "Epoch 257/1500\n",
      "8/8 - 0s - loss: 0.0607 - acc: 0.9630 - 468ms/epoch - 59ms/step\n",
      "Epoch 258/1500\n",
      "8/8 - 0s - loss: 0.0611 - acc: 0.9398 - 483ms/epoch - 60ms/step\n",
      "Epoch 259/1500\n",
      "8/8 - 0s - loss: 0.0632 - acc: 0.9259 - 479ms/epoch - 60ms/step\n",
      "Epoch 260/1500\n",
      "8/8 - 1s - loss: 0.0615 - acc: 0.9398 - 537ms/epoch - 67ms/step\n",
      "Epoch 261/1500\n",
      "8/8 - 0s - loss: 0.0628 - acc: 0.9491 - 486ms/epoch - 61ms/step\n",
      "Epoch 262/1500\n",
      "8/8 - 0s - loss: 0.0648 - acc: 0.9352 - 455ms/epoch - 57ms/step\n",
      "Epoch 263/1500\n",
      "8/8 - 1s - loss: 0.0664 - acc: 0.9352 - 579ms/epoch - 72ms/step\n",
      "Epoch 264/1500\n",
      "8/8 - 1s - loss: 0.0641 - acc: 0.9259 - 542ms/epoch - 68ms/step\n",
      "Epoch 265/1500\n",
      "8/8 - 1s - loss: 0.0645 - acc: 0.9306 - 512ms/epoch - 64ms/step\n",
      "Epoch 266/1500\n",
      "8/8 - 0s - loss: 0.0626 - acc: 0.9444 - 482ms/epoch - 60ms/step\n",
      "Epoch 267/1500\n",
      "8/8 - 0s - loss: 0.0631 - acc: 0.9444 - 479ms/epoch - 60ms/step\n",
      "Epoch 268/1500\n",
      "8/8 - 0s - loss: 0.0594 - acc: 0.9630 - 476ms/epoch - 59ms/step\n",
      "Epoch 269/1500\n",
      "8/8 - 0s - loss: 0.0596 - acc: 0.9769 - 500ms/epoch - 62ms/step\n",
      "Epoch 270/1500\n",
      "8/8 - 0s - loss: 0.0621 - acc: 0.9537 - 486ms/epoch - 61ms/step\n",
      "Epoch 271/1500\n",
      "8/8 - 1s - loss: 0.0640 - acc: 0.9259 - 541ms/epoch - 68ms/step\n",
      "Epoch 272/1500\n",
      "8/8 - 1s - loss: 0.0647 - acc: 0.9259 - 528ms/epoch - 66ms/step\n",
      "Epoch 273/1500\n",
      "8/8 - 0s - loss: 0.0625 - acc: 0.9306 - 480ms/epoch - 60ms/step\n",
      "Epoch 274/1500\n",
      "8/8 - 0s - loss: 0.0627 - acc: 0.9352 - 467ms/epoch - 58ms/step\n",
      "Epoch 275/1500\n",
      "8/8 - 0s - loss: 0.0616 - acc: 0.9352 - 500ms/epoch - 62ms/step\n",
      "Epoch 276/1500\n",
      "8/8 - 1s - loss: 0.0615 - acc: 0.9583 - 631ms/epoch - 79ms/step\n",
      "Epoch 277/1500\n",
      "8/8 - 1s - loss: 0.0652 - acc: 0.9306 - 650ms/epoch - 81ms/step\n",
      "Epoch 278/1500\n",
      "8/8 - 0s - loss: 0.0597 - acc: 0.9444 - 489ms/epoch - 61ms/step\n",
      "Epoch 279/1500\n",
      "8/8 - 0s - loss: 0.0591 - acc: 0.9398 - 497ms/epoch - 62ms/step\n",
      "Epoch 280/1500\n",
      "8/8 - 0s - loss: 0.0585 - acc: 0.9537 - 486ms/epoch - 61ms/step\n",
      "Epoch 281/1500\n",
      "8/8 - 0s - loss: 0.0595 - acc: 0.9537 - 490ms/epoch - 61ms/step\n",
      "Epoch 282/1500\n",
      "8/8 - 0s - loss: 0.0595 - acc: 0.9491 - 492ms/epoch - 61ms/step\n",
      "Epoch 283/1500\n",
      "8/8 - 0s - loss: 0.0591 - acc: 0.9444 - 481ms/epoch - 60ms/step\n",
      "Epoch 284/1500\n",
      "8/8 - 0s - loss: 0.0563 - acc: 0.9491 - 496ms/epoch - 62ms/step\n",
      "Epoch 285/1500\n",
      "8/8 - 0s - loss: 0.0555 - acc: 0.9306 - 465ms/epoch - 58ms/step\n",
      "Epoch 286/1500\n",
      "8/8 - 1s - loss: 0.0559 - acc: 0.9352 - 767ms/epoch - 96ms/step\n",
      "Epoch 287/1500\n",
      "8/8 - 1s - loss: 0.0614 - acc: 0.9537 - 515ms/epoch - 64ms/step\n",
      "Epoch 288/1500\n",
      "8/8 - 1s - loss: 0.0617 - acc: 0.9444 - 583ms/epoch - 73ms/step\n",
      "Epoch 289/1500\n",
      "8/8 - 1s - loss: 0.0603 - acc: 0.9306 - 502ms/epoch - 63ms/step\n",
      "Epoch 290/1500\n",
      "8/8 - 0s - loss: 0.0578 - acc: 0.9537 - 488ms/epoch - 61ms/step\n",
      "Epoch 291/1500\n",
      "8/8 - 0s - loss: 0.0576 - acc: 0.9491 - 491ms/epoch - 61ms/step\n",
      "Epoch 292/1500\n",
      "8/8 - 1s - loss: 0.0558 - acc: 0.9676 - 518ms/epoch - 65ms/step\n",
      "Epoch 293/1500\n",
      "8/8 - 1s - loss: 0.0614 - acc: 0.9398 - 509ms/epoch - 64ms/step\n",
      "Epoch 294/1500\n",
      "8/8 - 0s - loss: 0.0599 - acc: 0.9352 - 476ms/epoch - 59ms/step\n",
      "Epoch 295/1500\n",
      "8/8 - 0s - loss: 0.0614 - acc: 0.9259 - 490ms/epoch - 61ms/step\n",
      "Epoch 296/1500\n",
      "8/8 - 0s - loss: 0.0632 - acc: 0.9259 - 482ms/epoch - 60ms/step\n",
      "Epoch 297/1500\n",
      "8/8 - 0s - loss: 0.0560 - acc: 0.9352 - 484ms/epoch - 60ms/step\n",
      "Epoch 298/1500\n",
      "8/8 - 0s - loss: 0.0562 - acc: 0.9583 - 489ms/epoch - 61ms/step\n",
      "Epoch 299/1500\n",
      "8/8 - 1s - loss: 0.0603 - acc: 0.9444 - 504ms/epoch - 63ms/step\n",
      "Epoch 300/1500\n",
      "8/8 - 1s - loss: 0.0603 - acc: 0.9259 - 522ms/epoch - 65ms/step\n",
      "Epoch 301/1500\n",
      "8/8 - 0s - loss: 0.0582 - acc: 0.9630 - 482ms/epoch - 60ms/step\n",
      "Epoch 302/1500\n",
      "8/8 - 0s - loss: 0.0603 - acc: 0.9444 - 487ms/epoch - 61ms/step\n",
      "Epoch 303/1500\n",
      "8/8 - 0s - loss: 0.0586 - acc: 0.9583 - 485ms/epoch - 61ms/step\n",
      "Epoch 304/1500\n",
      "8/8 - 0s - loss: 0.0602 - acc: 0.9583 - 469ms/epoch - 59ms/step\n",
      "Epoch 305/1500\n",
      "8/8 - 0s - loss: 0.0553 - acc: 0.9630 - 480ms/epoch - 60ms/step\n",
      "Epoch 306/1500\n",
      "8/8 - 0s - loss: 0.0576 - acc: 0.9491 - 478ms/epoch - 60ms/step\n",
      "Epoch 307/1500\n",
      "8/8 - 0s - loss: 0.0608 - acc: 0.9444 - 479ms/epoch - 60ms/step\n",
      "Epoch 308/1500\n",
      "8/8 - 1s - loss: 0.0588 - acc: 0.9444 - 555ms/epoch - 69ms/step\n",
      "Epoch 309/1500\n",
      "8/8 - 0s - loss: 0.0582 - acc: 0.9398 - 480ms/epoch - 60ms/step\n",
      "Epoch 310/1500\n",
      "8/8 - 0s - loss: 0.0565 - acc: 0.9537 - 488ms/epoch - 61ms/step\n",
      "Epoch 311/1500\n",
      "8/8 - 0s - loss: 0.0561 - acc: 0.9583 - 476ms/epoch - 59ms/step\n",
      "Epoch 312/1500\n",
      "8/8 - 1s - loss: 0.0520 - acc: 0.9491 - 504ms/epoch - 63ms/step\n",
      "Epoch 313/1500\n",
      "8/8 - 1s - loss: 0.0565 - acc: 0.9444 - 505ms/epoch - 63ms/step\n",
      "Epoch 314/1500\n",
      "8/8 - 0s - loss: 0.0553 - acc: 0.9583 - 489ms/epoch - 61ms/step\n",
      "Epoch 315/1500\n",
      "8/8 - 0s - loss: 0.0560 - acc: 0.9630 - 497ms/epoch - 62ms/step\n",
      "Epoch 316/1500\n",
      "8/8 - 1s - loss: 0.0564 - acc: 0.9398 - 545ms/epoch - 68ms/step\n",
      "Epoch 317/1500\n",
      "8/8 - 1s - loss: 0.0583 - acc: 0.9398 - 510ms/epoch - 64ms/step\n",
      "Epoch 318/1500\n",
      "8/8 - 1s - loss: 0.0560 - acc: 0.9259 - 524ms/epoch - 65ms/step\n",
      "Epoch 319/1500\n",
      "8/8 - 0s - loss: 0.0565 - acc: 0.9352 - 490ms/epoch - 61ms/step\n",
      "Epoch 320/1500\n",
      "8/8 - 1s - loss: 0.0545 - acc: 0.9306 - 506ms/epoch - 63ms/step\n",
      "Epoch 321/1500\n",
      "8/8 - 1s - loss: 0.0537 - acc: 0.9491 - 700ms/epoch - 87ms/step\n",
      "Epoch 322/1500\n",
      "8/8 - 1s - loss: 0.0517 - acc: 0.9676 - 529ms/epoch - 66ms/step\n",
      "Epoch 323/1500\n",
      "8/8 - 1s - loss: 0.0516 - acc: 0.9491 - 521ms/epoch - 65ms/step\n",
      "Epoch 324/1500\n",
      "8/8 - 0s - loss: 0.0554 - acc: 0.9537 - 483ms/epoch - 60ms/step\n",
      "Epoch 325/1500\n",
      "8/8 - 0s - loss: 0.0562 - acc: 0.9352 - 488ms/epoch - 61ms/step\n",
      "Epoch 326/1500\n",
      "8/8 - 1s - loss: 0.0570 - acc: 0.9444 - 502ms/epoch - 63ms/step\n",
      "Epoch 327/1500\n",
      "8/8 - 1s - loss: 0.0552 - acc: 0.9444 - 511ms/epoch - 64ms/step\n",
      "Epoch 328/1500\n",
      "8/8 - 1s - loss: 0.0575 - acc: 0.9398 - 639ms/epoch - 80ms/step\n",
      "Epoch 329/1500\n",
      "8/8 - 1s - loss: 0.0548 - acc: 0.9537 - 602ms/epoch - 75ms/step\n",
      "Epoch 330/1500\n",
      "8/8 - 1s - loss: 0.0534 - acc: 0.9583 - 503ms/epoch - 63ms/step\n",
      "Epoch 331/1500\n",
      "8/8 - 1s - loss: 0.0522 - acc: 0.9537 - 511ms/epoch - 64ms/step\n",
      "Epoch 332/1500\n",
      "8/8 - 1s - loss: 0.0559 - acc: 0.9537 - 712ms/epoch - 89ms/step\n",
      "Epoch 333/1500\n",
      "8/8 - 0s - loss: 0.0568 - acc: 0.9722 - 481ms/epoch - 60ms/step\n",
      "Epoch 334/1500\n",
      "8/8 - 0s - loss: 0.0542 - acc: 0.9676 - 485ms/epoch - 61ms/step\n",
      "Epoch 335/1500\n",
      "8/8 - 0s - loss: 0.0555 - acc: 0.9630 - 483ms/epoch - 60ms/step\n",
      "Epoch 336/1500\n",
      "8/8 - 0s - loss: 0.0534 - acc: 0.9491 - 498ms/epoch - 62ms/step\n",
      "Epoch 337/1500\n",
      "8/8 - 1s - loss: 0.0538 - acc: 0.9444 - 697ms/epoch - 87ms/step\n",
      "Epoch 338/1500\n",
      "8/8 - 1s - loss: 0.0523 - acc: 0.9676 - 508ms/epoch - 63ms/step\n",
      "Epoch 339/1500\n",
      "8/8 - 1s - loss: 0.0550 - acc: 0.9491 - 563ms/epoch - 70ms/step\n",
      "Epoch 340/1500\n",
      "8/8 - 1s - loss: 0.0528 - acc: 0.9444 - 566ms/epoch - 71ms/step\n",
      "Epoch 341/1500\n",
      "8/8 - 0s - loss: 0.0554 - acc: 0.9398 - 478ms/epoch - 60ms/step\n",
      "Epoch 342/1500\n",
      "8/8 - 1s - loss: 0.0535 - acc: 0.9444 - 554ms/epoch - 69ms/step\n",
      "Epoch 343/1500\n",
      "8/8 - 1s - loss: 0.0542 - acc: 0.9583 - 588ms/epoch - 73ms/step\n",
      "Epoch 344/1500\n",
      "8/8 - 0s - loss: 0.0566 - acc: 0.9583 - 475ms/epoch - 59ms/step\n",
      "Epoch 345/1500\n",
      "8/8 - 0s - loss: 0.0550 - acc: 0.9583 - 486ms/epoch - 61ms/step\n",
      "Epoch 346/1500\n",
      "8/8 - 1s - loss: 0.0550 - acc: 0.9398 - 519ms/epoch - 65ms/step\n",
      "Epoch 347/1500\n",
      "8/8 - 1s - loss: 0.0546 - acc: 0.9630 - 526ms/epoch - 66ms/step\n",
      "Epoch 348/1500\n",
      "8/8 - 1s - loss: 0.0589 - acc: 0.9537 - 520ms/epoch - 65ms/step\n",
      "Epoch 349/1500\n",
      "8/8 - 0s - loss: 0.0522 - acc: 0.9444 - 490ms/epoch - 61ms/step\n",
      "Epoch 350/1500\n",
      "8/8 - 0s - loss: 0.0555 - acc: 0.9352 - 489ms/epoch - 61ms/step\n",
      "Epoch 351/1500\n",
      "8/8 - 1s - loss: 0.0569 - acc: 0.9491 - 559ms/epoch - 70ms/step\n",
      "Epoch 352/1500\n",
      "8/8 - 1s - loss: 0.0549 - acc: 0.9537 - 502ms/epoch - 63ms/step\n",
      "Epoch 353/1500\n",
      "8/8 - 0s - loss: 0.0545 - acc: 0.9676 - 494ms/epoch - 62ms/step\n",
      "Epoch 354/1500\n",
      "8/8 - 1s - loss: 0.0526 - acc: 0.9630 - 501ms/epoch - 63ms/step\n",
      "Epoch 355/1500\n",
      "8/8 - 0s - loss: 0.0569 - acc: 0.9352 - 499ms/epoch - 62ms/step\n",
      "Epoch 356/1500\n",
      "8/8 - 1s - loss: 0.0538 - acc: 0.9583 - 501ms/epoch - 63ms/step\n",
      "Epoch 357/1500\n",
      "8/8 - 1s - loss: 0.0543 - acc: 0.9722 - 502ms/epoch - 63ms/step\n",
      "Epoch 358/1500\n",
      "8/8 - 1s - loss: 0.0523 - acc: 0.9491 - 514ms/epoch - 64ms/step\n",
      "Epoch 359/1500\n",
      "8/8 - 1s - loss: 0.0524 - acc: 0.9352 - 508ms/epoch - 64ms/step\n",
      "Epoch 360/1500\n",
      "8/8 - 0s - loss: 0.0554 - acc: 0.9352 - 494ms/epoch - 62ms/step\n",
      "Epoch 361/1500\n",
      "8/8 - 1s - loss: 0.0521 - acc: 0.9398 - 530ms/epoch - 66ms/step\n",
      "Epoch 362/1500\n",
      "8/8 - 1s - loss: 0.0548 - acc: 0.9583 - 509ms/epoch - 64ms/step\n",
      "Epoch 363/1500\n",
      "8/8 - 1s - loss: 0.0524 - acc: 0.9491 - 505ms/epoch - 63ms/step\n",
      "Epoch 364/1500\n",
      "8/8 - 1s - loss: 0.0544 - acc: 0.9630 - 507ms/epoch - 63ms/step\n",
      "Epoch 365/1500\n",
      "8/8 - 0s - loss: 0.0516 - acc: 0.9398 - 496ms/epoch - 62ms/step\n",
      "Epoch 366/1500\n",
      "8/8 - 1s - loss: 0.0521 - acc: 0.9583 - 508ms/epoch - 63ms/step\n",
      "Epoch 367/1500\n",
      "8/8 - 1s - loss: 0.0539 - acc: 0.9444 - 511ms/epoch - 64ms/step\n",
      "Epoch 368/1500\n",
      "8/8 - 1s - loss: 0.0564 - acc: 0.9537 - 512ms/epoch - 64ms/step\n",
      "Epoch 369/1500\n",
      "8/8 - 1s - loss: 0.0541 - acc: 0.9583 - 513ms/epoch - 64ms/step\n",
      "Epoch 00369: early stopping\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "history=model.fit(train, label, batch_size=BATCHSIZE, epochs=EPOCH, verbose=2, callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonction de perte "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#capture 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.legend(['train_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prédiction du tirage suivant le dernier tirage de notre dataset de train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\free\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Prediction basée sur les 12 derniers tirages\n",
    "last_twelve = df.tail(window_length) # on recupere les 12 derniers tirages\n",
    "scaler = StandardScaler().fit(df.values)\n",
    "scaled_to_predict = scaler.transform(last_twelve)\n",
    "scaled_predicted_output_1 = model.predict(np.array([scaled_to_predict]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction\n",
    "tom = df.tail(window_length).iloc[:,0:6] # \n",
    "scaler = StandardScaler().fit(df.iloc[:,0:6])\n",
    "scaled_to_predict = scaler.transform(tom)\n",
    "print(scaler.inverse_transform(scaled_predicted_output_1).astype(int)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
